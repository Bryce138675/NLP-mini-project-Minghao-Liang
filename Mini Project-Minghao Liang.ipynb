{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4620f2",
   "metadata": {},
   "source": [
    "# Import and clean the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e97d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c8e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\22046163\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bs4 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22081bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('lyrics2.tsv','r',encoding='utf-8')\n",
    "#file=open('lyrics2.tsv')\n",
    "dataset=np.loadtxt(file,delimiter=\"\\t\",dtype='O')\n",
    "#headings = dataset[0]\n",
    "dataset = dataset[1:]\n",
    "\n",
    "dataset[:, 1] = [x.replace(\",\", \"->\").replace('\"\\u200b',' ').replace('\\u200b',' ').replace(\"'\",'').strip().split(\"->\")[0] for x in dataset[:, 1]]\n",
    "dataset[:, 2] = [x.replace(\",\", \"->\").replace('\\u200b',' ').replace(\"'\",'').strip().split(\"->\")[0] for x in dataset[:, 2]]\n",
    "Singer=dataset[:,0]\n",
    "song_title=dataset[:,1]\n",
    "Album=dataset[:,2]\n",
    "Date=dataset[:,4]\n",
    "lyrics=dataset[:,5]\n",
    "#print(song_title)\n",
    "song_lyrics=dataset[:,5]\n",
    "#print(song_lyrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbecd1cb",
   "metadata": {},
   "source": [
    "# Daily Greeting Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6b2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily greeting\n",
    "def Lyrics_Bot(msgText):\n",
    "    reg=r\"Hello\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"Hello back!\")\n",
    "        return\n",
    "    reg=r\"How are you\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"I'm great. How about you?\")\n",
    "        return\n",
    "    reg=r\"Hi\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"Hi!\")\n",
    "        return\n",
    "    reg=r\"Nice to meet you\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"Nice to meet you, too!\")\n",
    "        return\n",
    "    reg=r\"what's your name?\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"My name is Lyric!\")\n",
    "        return\n",
    "    reg=r\"Hello\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"Hello back\")\n",
    "        return\n",
    "    reg=r\"Good morning\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"Good morning\")\n",
    "        return\n",
    "    reg=r\"How do you do?\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"I’m doing well thank you\")\n",
    "        return\n",
    "    reg=r\"Thank you\"\n",
    "    m=re.search(reg,msgText)\n",
    "    if m :\n",
    "        print(\"No worries\")\n",
    "        return\n",
    "    print(\"Sorry, I didn't understand you!\")\n",
    "  \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7d5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lyrics_Bot('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401b437",
   "metadata": {},
   "source": [
    "# Use input function to introduce some information about music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3228f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name:\n",
      "Bryce\n",
      "Hello, Bryce! My name is Lyric.\n"
     ]
    }
   ],
   "source": [
    "#Daily greeting(Input)\n",
    "print(\"Enter your name:\")\n",
    "x = input()\n",
    "print(\"Hello, \" + x+\"! My name is Lyric.\")\n",
    "# For example, I enter my name---Bryce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5250e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter kind of music(initial capitalization):\n",
      "Pop music\n",
      "Pop music is distinguished from chart music. Identifying factors usually include repeated choruses and hooks, short to medium-length songs written in a basic format (often the verse-chorus structure), and rhythms or tempos that can be easily danced to. \n"
     ]
    }
   ],
   "source": [
    "# Information about some kind of music\n",
    "print(\"Enter kind of music(initial capitalization):\")\n",
    "x = input()\n",
    "if x==\"Rock music\":\n",
    "    print(x+\" is song-based music using a verse–chorus form, but the genre has become extremely diverse. Like pop music, lyrics often stress romantic love but also address a wide variety of other themes that are frequently social or political. \")\n",
    "elif x==\"Pop music\":\n",
    "    print(x+\" is distinguished from chart music. Identifying factors usually include repeated choruses and hooks, short to medium-length songs written in a basic format (often the verse-chorus structure), and rhythms or tempos that can be easily danced to. \")\n",
    "elif x==\"Jazz music\":\n",
    "    print(x+\" is music that includes qualities such as swing, improvising, group interaction, developing an 'individual voice', and being open to different musical possibilities\")\n",
    "elif x==\"Folk music\":\n",
    "    print(x+\" is a music genre that includes traditional folk music and the contemporary genre that evolved from the former during the 20th-century folk revival.\")\n",
    "elif x==\"Electronic music\":\n",
    "    print(x+\" is a genre of music that employs electronic musical instruments, digital instruments, or circuitry-based music technology in its creation. \")\n",
    "elif x==\"Rap music\":\n",
    "    print(x+\" consists of stylized rhythmic music (usually built around drum beats) that commonly accompanies rapping, a rhythmic and rhyming speech that is chanted.\")\n",
    "elif x==\"Metal music\":\n",
    "    print(x+\" developed a thick, monumental sound characterized by distorted guitars, extended guitar solos, emphatic beats and loudness.\")\n",
    "elif x==\"Classical music\":\n",
    "    print(x+\" is often characterized by formality and complexity in its musical form and harmonic organization, particularly with the use of polyphony.\")\n",
    "else:\n",
    "    print(\"Sorry, other kinds of music will be added recently\")\n",
    "#For example, I enter Pop music \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955f390",
   "metadata": {},
   "source": [
    "# Find lyrics、title、album and singer of songs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233bb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find lyrics by song title\n",
    "def research_lyrics(c):\n",
    "    arr=np.array(song_title)\n",
    "    filter_arr=[]\n",
    "    for i in range(len(song_title)):\n",
    "        if song_title[int(i)]==c:\n",
    "            print(song_lyrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34b5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the title of songs into '' and remove the '#'\n",
    "#research_lyrics('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8558412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find lyrics and songs by Album\n",
    "def research_lyricsandsongs(d):\n",
    "    arr=np.array(Album)\n",
    "    filter_arr=[]\n",
    "    for i in range(len(Album)):\n",
    "        if Album[int(i)]==d:\n",
    "            print(\"The songs on the album are:\")\n",
    "            print(song_title[i])\n",
    "            print(\"The lyrics on the album are:\")\n",
    "            print(song_lyrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be443f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the title of Album into '' and remove the '#'\n",
    "#research_lyricsandsongs('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Albums by singer\n",
    "def research_Album(h):\n",
    "    arr = np.array(Singer)\n",
    "    #print(len(Singer))\n",
    "    filter_arr = []\n",
    "    for i in range(len(Singer)):\n",
    "        if Singer[int(i)] == h:\n",
    "            if Album[i]=='':\n",
    "                continue\n",
    "            h_Album = Album[i]\n",
    "            # print(h_Album)\n",
    "            filter_arr.append(h_Album)\n",
    "            # print(type(h_Album))\n",
    "\n",
    "        mode_Album = Counter(filter_arr).most_common(100)\n",
    "            # print(mode_Album)\n",
    "            # print(h_Album)\n",
    "    return mode_Album\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29fff57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the title of singers into '' and remove the '#'\n",
    "#print(\"All of the singer's albums are：\")\n",
    "#print(research_Album('Ariana Grande'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d155b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Singer by Song title and open the website about the song of singer\n",
    "import requests\n",
    "def research_title(y):\n",
    "    #print(g)\n",
    "    arr=np.array(song_title)\n",
    "    filter_arr=[]\n",
    "    for i in range(len(song_title)):\n",
    "        if song_title[int(i)]==y:\n",
    "            return Singer[i]\n",
    "       \n",
    "        t=Singer[i]\n",
    "        t1=t.split()\n",
    "        First_name=str(t1[0])\n",
    "        Last_name=str(t1[1])\n",
    "        Last_name2=Last_name.lower()\n",
    "        print(\"This is the website to listen this song and lyrics:\")\n",
    "        print('https://genius.com/'+First_name+'-'+Last_name2)\n",
    "        print(\"This are some information about this singer on wikipedia:\")\n",
    "        print(\"https://en.wikipedia.org/wiki/\"+First_name+'_'+Last_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86f13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the title of singers into '' and remove the '#'\n",
    "#research_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8668886",
   "metadata": {},
   "source": [
    "# Use the coding to analyse the emotions of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a4fac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Study how to detect emotions from textual data (https://towardsdatascience.com/text2emotion-python-package-to-detect-emotions-from-textual-data-b2e7b7ce1153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c399842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: text2emotion in c:\\users\\22046163\\anaconda3\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: emoji>=0.6.0 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from text2emotion) (1.6.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from text2emotion) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from nltk->text2emotion) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from nltk->text2emotion) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from nltk->text2emotion) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from nltk->text2emotion) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from click->nltk->text2emotion) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install text2emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d50b38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji~=1.6.3 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (1.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji~=1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ab76cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\22046163\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\22046163\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\22046163\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b59b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def a function to analyse the emotion of the song which you want\n",
    "def research_lyrics(h):\n",
    "    arr=np.array(song_title)\n",
    "    filter_arr=[]\n",
    "    for i in range(len(song_title)):\n",
    "        if song_title[int(i)]==h:\n",
    "            #print(song_lyrics[i])\n",
    "            text_h=song_lyrics[i]\n",
    "            text_emotion=te.get_emotion(text_h)\n",
    "            print(text_emotion)\n",
    "            #print(text_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcdd14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to find the emotion of songs, please remove the \"#\" and enter the title of songs into '' \n",
    "#research_lyrics('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc5a7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse all emotions of songs\n",
    "\n",
    "#filter_arr=[]\n",
    "#for n in range(len(lyrics)):\n",
    "    #text_n=lyrics[n]\n",
    "    #filter_arr.append(text_n)\n",
    "            # print(type(h_Album))\n",
    "    #t=te.get_emotion(text_n)\n",
    "    \n",
    "    #print(type(t))\n",
    "# It will need a lot of time to analyse all emotions of songs, so I use '#' to keep the coding run. \n",
    "#If you want to see the result, you could remove \"#\". \n",
    "    #print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e41fbd",
   "metadata": {},
   "source": [
    "# Compare the similarity lyrics between different singers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e7a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, we find the mose similar songs between Ariana_Grande and Drake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98702228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required for colab and possibly other contexts:\n",
    "import re \n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89add39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\22046163\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required if you haven't done this before:\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4d0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required for everyone always:\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import _stop_words as stop_words\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de30eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If there are some mistakes, you can try to install NLTK Data and remove the \"#\". (https://www.nltk.org/data.html)\n",
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83cb9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_csv=pd.read_csv('tsv/Ariana_Grande.tsv',encoding='utf-8') #Reads a CSV file into a pandas dataframe\n",
    "#show us the first 3 rows if you want \n",
    "#data_from_csv.sample(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f55e1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's rename the lyrics column to \"text\" so we can easily access it later\n",
    "df=data_from_csv.rename(columns={'Song title':'text'})\n",
    "# you can see the sample by removing the \"#\" if you want\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a381f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Called once for each document\n",
    "#Every time you update this function you need to run the cell again (Shift + Enter)]\n",
    "lem = WordNetLemmatizer()\n",
    "def my_tokeniser(doc):\n",
    "    #Split on spaces\n",
    "    tokens = re.split(r'[-\\s.,;!?]+', doc)\n",
    "    return [lem.lemmatize(t.lower()) for t in tokens if not t in stop_words.ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9960a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectoriser=TfidfVectorizer(tokenizer=my_tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af2cfd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\22046163\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\22046163\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ddfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in lyrics \n",
    "Ariana_Grande=pd.read_csv('tsv/Ariana_Grande.tsv',delimiter=\"\\t\")\n",
    "Ariana_Grande=Ariana_Grande[[\"Song title\", \"lyrics\"]]\n",
    "Ariana_Grande.columns=[\"Title\",\"Lyrics\"]\n",
    "#Add artist into title field\n",
    "Ariana_Grande[\"Title\"]=\"Ariana_Grande: \"+Ariana_Grande[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f0612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Ariana_Grande: ​thank u, next\n",
       "1                                 Ariana_Grande: 7 rings\n",
       "2                         Ariana_Grande: ​God is a woman\n",
       "3                            Ariana_Grande: Side To Side\n",
       "4                  Ariana_Grande: ​​no tears left to cry\n",
       "                             ...                        \n",
       "300    Ariana_Grande: God is a Woman (Excuse me i lov...\n",
       "301                                Ariana_Grande: Magic*\n",
       "302                            Ariana_Grande: Right here\n",
       "303                               Ariana_Grande: Venuss*\n",
       "304    Ariana_Grande: One last time_Ariana_Grande_(2014)\n",
       "Name: Title, Length: 305, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ariana_Grande['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58749c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in lyrics \n",
    "Drake=pd.read_csv('tsv/Drake.tsv',delimiter=\"\\t\")\n",
    "Drake=Drake[[\"Song title\", \"lyrics\"]]\n",
    "Drake.columns=[\"Title\",\"Lyrics\"]\n",
    "#Add artist into title field\n",
    "Drake[\"Title\"]=\"Drake: \"+Drake[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c388021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     Drake: God’s Plan\n",
       "1                 Drake: In My Feelings\n",
       "2                  Drake: Hotline Bling\n",
       "3                      Drake: One Dance\n",
       "4      Drake: Hold On, We’re Going Home\n",
       "                     ...               \n",
       "461       Drake: Real Her (Single Leak)\n",
       "462         Drake: Love From a Distance\n",
       "463                     Drake: Dementia\n",
       "464      Drake: Legendary Shit prod NFF\n",
       "465                  Drake: Why I curse\n",
       "Name: Title, Length: 466, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Drake['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c94942db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join title lists together\n",
    "titles=[]\n",
    "for t in Ariana_Grande[\"Title\"]:\n",
    "    titles.append(t)\n",
    "for t in Drake[\"Title\"]:\n",
    "    titles.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44169c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join lyric lists together\n",
    "lyrics=[]\n",
    "for l in Ariana_Grande[\"Lyrics\"]:\n",
    "    lyrics.append(l)\n",
    "for t in Drake[\"Lyrics\"]:\n",
    "    lyrics.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb2291c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 771)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles),len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "838513f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf\n",
    "\n",
    "tfidf_vectoriser = TfidfVectorizer(tokenizer=my_tokeniser)\n",
    "tfidf = tfidf_vectoriser.fit_transform(lyrics)\n",
    "tfidf_df = pd.DataFrame(tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e09ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fe1a8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 771)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get similarity\n",
    "sim=cosine(tfidf_df)\n",
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4e39e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 771)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort each row by what is the most similar, store the indexes(not the values)\n",
    "sort=np.argsort(sim)\n",
    "sort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10670628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Docementation for argsort methods\n",
    "?np.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "090c84fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort, take second to last value because most similar will be thesame song\n",
    "best=sort[:,-2]\n",
    "best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fc76601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best match is  Ariana_Grande: One last time_Ariana_Grande_(2014) .vs. Drake: Paris Morton Music with a similarity of 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "#Intialise some variables\n",
    "best_match = 0\n",
    "best_titles = \"\"\n",
    "best_indexes = (0,0)\n",
    "\n",
    "#Got through matches\n",
    "for i, most_sim in enumerate(best):\n",
    "    #Join titles together\n",
    "    match = titles[i] + \" .vs. \" + titles[most_sim]\n",
    "    #Do the titles joined together include both artists?\n",
    "    if \"Ariana_Grande\" in match and \" Drake\" in match:\n",
    "        similarity = sim[i,most_sim]\n",
    "        #If highest match so far, update\n",
    "        if similarity > best_match:\n",
    "            best_match = similarity\n",
    "            #Save title and indexes (to view at the end)\n",
    "            best_titles = match\n",
    "            best_indexes = (i,most_sim)\n",
    "        #print(match, similarity)\n",
    " \n",
    "print(\"best match is \", best_titles, \"with a similarity of\", best_match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62d1ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def a function to analyse the emotion of the song which you want\n",
    "def research_lyrics(h):\n",
    "    arr=np.array(song_title)\n",
    "    filter_arr=[]\n",
    "    for i in range(len(song_title)):\n",
    "        if song_title[int(i)]==h:\n",
    "            #print(song_lyrics[i])\n",
    "            text_h=song_lyrics[i]\n",
    "            text_emotion=te.get_emotion(text_h)\n",
    "            print(text_emotion)\n",
    "            #print(text_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca1f076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emotion of One last time_Ariana_Grande_(2014) is \n",
      "{'Happy': 0.0, 'Angry': 0.22, 'Surprise': 0.16, 'Sad': 0.51, 'Fear': 0.11}\n",
      "The emotion of Paris Morton Music is \n",
      "{'Happy': 0.11, 'Angry': 0.11, 'Surprise': 0.25, 'Sad': 0.23, 'Fear': 0.32}\n"
     ]
    }
   ],
   "source": [
    "#Then we can compare the emotion of the most similar songs\n",
    "print(\"The emotion of One last time_Ariana_Grande_(2014) is \")\n",
    "research_lyrics('One last time_Ariana_Grande_(2014)')\n",
    "print(\"The emotion of Paris Morton Music is \")\n",
    "research_lyrics('Paris Morton Music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a06eb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just used an example to analyse the relationship between similar lyrics and emotions. If you would like to use another singers, you could change the name of singers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
